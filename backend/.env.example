# ─── Qdrant ───────────────────────────────────────────────────────────────────
QDRANT_URL=http://localhost:6333

# ─── Embedding (local GGUF via llama-cpp-python) ─────────────────────────────
EMBED_MODE=local
# For remote mode:
# EMBED_MODE=remote
# EMBED_API_URL=https://api.example.com/v1
# EMBED_API_KEY=your-api-key
# EMBED_MODEL_NAME=nomic-embed-text

# ─── LLM (local GGUF via llama-cpp-python) ────────────────────────────────────
LLM_MODE=local
# For remote mode:
# LLM_MODE=remote
# LLM_API_URL=https://api.example.com/v1
# LLM_API_KEY=your-api-key
# LLM_MODEL_NAME=distil-labs-slm

# ─── Cognee framework ────────────────────────────────────────────────────────
ENABLE_BACKEND_ACCESS_CONTROL=false
VECTOR_DB_PROVIDER=qdrant
VECTOR_DB_URL=http://localhost:6333
TELEMETRY_DISABLED=1

# Cognee LLM for cognify() knowledge graph extraction
LLM_API_KEY_COGNEE=your-openai-api-key
LLM_PROVIDER=openai
LLM_MODEL=gpt-4o-mini
LLM_ENDPOINT=https://api.openai.com/v1
